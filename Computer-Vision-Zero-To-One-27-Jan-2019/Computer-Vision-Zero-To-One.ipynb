{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer-Zero-To-One\n",
    "---\n",
    "This Jupyter Notebook contains code used for the [Computer-Vision-Zero-To-One](https://www.facebook.com/events/627284531033840/) hands-on session on computer vision by [Pratik Gujral](https://pratikgujral.com/) for [Facebook Developer Circle: Delhi, NCR](https://www.facebook.com/groups/DevCDelhiNCR/) on January 27, 2019 at Innovaccer Noida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and displaying an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## Color image\n",
    "img = cv2.imread('Penguins.jpg')\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## Converting to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('image', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "## To write the image\n",
    "#cv2.imwrite('Penguins_GrayScale', gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and displaying a video\n",
    "- Read and display a video stored on disk.\n",
    "- Video from Camera\n",
    "- 0xFF introduced for the first time. https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('Wildlife.wmv')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        cv2.imshow('Video', frame)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == 27: # ASCII for Esc key.\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with pixels\n",
    "- Print the shape of colored, grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1024, 3)\n",
      "2359296\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('Penguins.jpg')\n",
    "#cv2.imshow('image', img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "## Shape for colored as well as grayscale\n",
    "print(img.shape)\n",
    "print(img.size) # Same as multiplying size across all dimensions\n",
    "print(img.dtype)\n",
    "\n",
    "\n",
    "## Making a patch of the image black\n",
    "img[100:200, 400:700, :] = 0\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "## Cropping the image\n",
    "cropped = img[60:730, 180:360]\n",
    "cv2.imshow('Cropped Image', cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,0,1,0,0,1,0,1,1,0,0,0,1])  ## FIND 0,1,1\n",
    "seq = np.array([0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.correlate(a, seq, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.correlate(a, seq, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing colorspaces\n",
    "- Something one would be doing often.\n",
    "- Exploit color information in an image\n",
    "- more than 250 color-space conversion methods available\n",
    "- Can be used for filtering based on color. Object tracking\n",
    "- We will create an application which extracts a colored object in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    }
   ],
   "source": [
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print(len(flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "penguin = cv2.imread('Penguins.jpg') # Display these images.\n",
    "template = cv2.imread('template.jpg')\n",
    "\n",
    "## We'll work on 2D. 3D is just a slight extension to what we are doing here\n",
    "penguin_gray = cv2.cvtColor(penguin, cv2.COLOR_BGR2GRAY)\n",
    "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY) # Display these images\n",
    "\n",
    "w, h = template_gray.shape[::-1]  ## We are going to need this later\n",
    "\n",
    "result = cv2.matchTemplate(penguin, template, method = cv2.TM_CCORR_NORMED)\n",
    "\n",
    "## All the 6 methods for comparison in a list. MENTION THIS AFTER RUNNING THE DEMO\n",
    "##  methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "##   'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "cv2.rectangle(penguin, top_left, bottom_right, (0,255,0), 2) # Rectangle on colored image\n",
    "\n",
    "cv2.imshow('image', penguin)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolution ( Image Filtering )\n",
    "- High frequency components in images->  edges\n",
    "- Like signals, images also can be filtered with various low-pass filters(LPF), high-pass filters(HPF) etc. \n",
    "- LPF helps in removing noises, blurring the images etc. HPF filters helps in finding edges in the images.\n",
    "\n",
    "### Averaging filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('Penguins.jpg')\n",
    "\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('img', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to the image\n",
    "noisy_img = np.uint8(img + np.random.normal(size = img.shape,  loc=0, scale=1))\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('noisy', noisy_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51246096, -1.22227086,  1.37566352, ..., -0.01036279,\n",
       "         0.70194426, -1.85019119],\n",
       "       [-2.40765148, -0.33235342,  1.08045131, ..., -0.28992798,\n",
       "        -1.94309093,  0.34559706],\n",
       "       [ 0.225147  ,  0.54421618,  1.32751479, ..., -1.79861136,\n",
       "         1.76925144, -0.10864271],\n",
       "       ...,\n",
       "       [ 0.23432127,  0.77992441, -0.92331496, ..., -0.05611111,\n",
       "         1.09757384,  0.38449933],\n",
       "       [-0.32081371, -0.57004448, -0.66804717, ..., -0.02644905,\n",
       "         0.94896458, -0.54367893],\n",
       "       [ 0.45969368,  0.60264194,  0.61689261, ..., -1.22681221,\n",
       "         0.15520306,  0.25509863]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size = img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(size = img.shape, scale=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_img = np.uint8(img +  noise)\n",
    "\n",
    "cv2.imshow('dwqe', noisy_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('pen_noise.jpg', cv2.cvtColor(noisy_img, cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 3) # Try with minNeighbors=5.\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('window', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection\n",
    "import cv2\n",
    "img = cv2.imread('road-lane.jpg',0) # Display the image\n",
    "\n",
    "threshold1 = 50\n",
    "threshold2 = 200\n",
    "\n",
    "edge_img = cv2.Canny(img, threshold1, threshold2)\n",
    "\n",
    "cv2.imshow('edge image', edge_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Lane Detection\n",
    "- Read and display road image\n",
    "- Canny edge detection and show output image\n",
    "- Now, apply blur, perform edge detection and then show the difference in output image\n",
    "- Masking (ROI)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('road-lane.jpg')\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "#cv2.imshow('img_gray', img_gray)\n",
    "\n",
    "# Smoothing the original image\n",
    "kernel_size = 11\n",
    "img_gray_blur = cv2.GaussianBlur(img_gray, (kernel_size,kernel_size), 0)\n",
    "cv2.imshow('img_gray_blur', img_gray_blur)\n",
    "\n",
    "low_threshold = 50\n",
    "high_threshold = 110\n",
    "\n",
    "img_gray_blur_edge = cv2.Canny(img_gray_blur, low_threshold, high_threshold, 5)\n",
    "cv2.imshow('edge', img_gray_blur_edge)\n",
    "\n",
    "mask = np.zeros(img_gray.shape, dtype=np.uint8)\n",
    "#roi_corners = np.array([[(10,10), (300,300), (10,300)]], dtype=np.int32)\n",
    "h, w = img_gray_blur_edge.shape\n",
    "#roi_corners = np.array([[(w/2,0.66*h), (0,h), (w,h)]], dtype=np.int32)\n",
    "roi_corners = np.array([[(.75*w,0.55*h),(.25*w,0.55*h), (0,0.9*h), (0,h), (w,h)]], dtype=np.int32)\n",
    "# fill the ROI so it doesn't get wiped out when the mask is applied\n",
    "#channel_count = img_gray.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "ignore_mask_color = (255,)\n",
    "cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "cv2.imshow('mask', mask)\n",
    "\n",
    "roi_img = cv2.bitwise_and(img_gray_blur_edge,mask)\n",
    "cv2.imshow('roi_img', roi_img)\n",
    "\n",
    "img_gray_blur_edge_bgr = cv2.cvtColor(img_gray_blur_edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "linesP = cv2.HoughLinesP(roi_img, 5, np.pi / 180, 100, None, 50, 130)\n",
    "if linesP is not None:\n",
    "    for i in range(0, len(linesP)):\n",
    "        l = linesP[i][0]\n",
    "        cv2.line(img, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('final', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "road = cv2.imread('road-lane.jpg')\n",
    "\n",
    "road_hsv = cv2.cvtColor(road, cv2.COLOR_BGR2HSV)  # Show \n",
    "\n",
    "cv2.imshow('roadimg',road)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
